# ğŸ  Ames Housing Price Prediction

## ğŸ“„ DescripciÃ³n
Este proyecto consiste en construir un modelo predictivo de precios de viviendas usando el conjunto de datos de Ames (Iowa, EE. UU.). Se aplicaron tÃ©cnicas de anÃ¡lisis exploratorio, limpieza de datos, ingenierÃ­a de caracterÃ­sticas y modelos lineales regularizados para predecir el **precio de venta** de las casas.

---

## ğŸ—‚ï¸ Acerca del conjunto de datos
El conjunto de datos de vivienda de Ames es un conjunto ampliamente reconocido en el campo del **aprendizaje automÃ¡tico** y el **anÃ¡lisis de datos**. Contiene diversas caracterÃ­sticas de las viviendas y se utiliza principalmente para tareas de regresiÃ³n.

- **NÃºmero de instancias:** 2.930 observaciones  
- **NÃºmero de caracterÃ­sticas:** 79 variables  
- **Variable objetivo:** `SalePrice` (Precio de venta)  
- **Tipos de datos:** NumÃ©ricas y categÃ³ricas (tamaÃ±o del lote, nÃºmero de habitaciones, ubicaciÃ³n, construcciÃ³n, etc.)  

Este dataset es ideal para **modelado predictivo, ingenierÃ­a de caracterÃ­sticas y anÃ¡lisis de regresiÃ³n**.

---

## ğŸ§° TecnologÃ­as y librerÃ­as utilizadas
- Python ğŸ  
- Pandas, NumPy  
- Matplotlib, Seaborn  
- Scikit-learn (LinearRegression, Lasso, Ridge, preprocessing)  

---

## ğŸ—ï¸ Flujo de trabajo / Pipeline
1. **EDA (Exploratory Data Analysis)** ğŸ”  
   - AnÃ¡lisis de distribuciones y outliers  
   - Correlaciones con `SalePrice_log`  
   - IdentificaciÃ³n de variables irrelevantes y multicolinealidad  

2. **Limpieza de datos** ğŸ§¹  
   - ImputaciÃ³n de valores faltantes (mediana para numÃ©ricas, moda para categÃ³ricas)  
   - EliminaciÃ³n de variables redundantes o altamente colineales  

3. **Feature Engineering** ğŸ› ï¸  
   - CodificaciÃ³n ordinal manual  
   - One-Hot Encoding para variables nominales  
   - SeparaciÃ³n clara entre features `X` y target `y`  

4. **Modelado** ğŸ§®  
   - CreaciÃ³n de pipeline completo:  
     ```python
     Pipeline([
         ("preprocessor", preprocessor),
         ("regressor", Model())
     ])
     ```
   - Ventajas: evita data leakage, reproducible, escalable, listo para producciÃ³n  

---

## ğŸ”œ Resultados principales
- Modelo ganador: **LASSO**  
- TRAIN RMSE (log): 0.1302960671229784  
- TEST RMSE (log): 0.11571793484987468  
- TRAIN RÂ²: 0.8944921714470315  
- TEST RÂ²: 0.9276296145781626  

> ğŸ’¡ Estas mÃ©tricas muestran un buen ajuste y capacidad de generalizaciÃ³n, pero todavÃ­a puedes completarlas con grÃ¡ficos de residuales y Real vs Predicho.

---

## ğŸ“ˆ EvaluaciÃ³n del modelo 
- GrÃ¡fico Real vs Predicho
![Real vs Predicho](Images/realvspredicho.png) 
### ğŸ”¹ Resumen basado en LASSO
- **TRAIN RMSE (log):** 0.1303  
- **TEST RMSE (log):** 0.1157  
- **TRAIN RÂ²:** 0.8945  
- **TEST RÂ²:** 0.9276  

### ğŸ”¹ Observaciones de los residuos
1. **DistribuciÃ³n aproximadamente normal:**  
   - La mayorÃ­a de los residuos se concentran alrededor de cero â†’ no hay sesgo sistemÃ¡tico.  

2. **Homoscedasticidad:**  
   - La dispersiÃ³n es relativamente constante a lo largo de los valores predichos. 

3. **Outliers detectados:**  
   - Algunas viviendas con precios extremos presentan residuos mayores.  
   - Estos casos pueden analizarse individualmente para ver si requieren ajuste.
  
### ğŸ”¹ ConclusiÃ³n
El modelo **LASSO**:
- Tiene buen poder predictivo  
- Generaliza bien a datos nuevos  
- No muestra problemas graves de heteroscedasticidad o sesgo 

---
## ğŸ“¬ Contacto


Si quieres **conectar**, colaborar o simplemente hablar de data science, ML o proyectos de anÃ¡lisis de datos, Â¡escrÃ­beme!  

- **LinkedIn:** [Camilo Pedreros](https://www.linkedin.com/in/camilo-pedreros-106a1a245/) ğŸ”—  
- **Correo:** [cpedreros488@gmail.com](cpedreros488@gmail.com) ğŸ“§  
- **GitHub:** [@CamiiloP14](https://github.com/CamiiloP14) ğŸ±  


